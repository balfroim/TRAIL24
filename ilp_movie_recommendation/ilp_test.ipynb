{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from models.csv_loader import CSVLoader\n",
    "from models.products.product_registry import ProductRegistry\n",
    "from models.products.product_mapping_row import ProductMappingRow\n",
    "from models.products.product_row import ProductRow\n",
    "\n",
    "product_registry = ProductRegistry(CSVLoader(ProductRow).read(), CSVLoader(ProductMappingRow).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.users.user_registry import UserRegistry\n",
    "from models.users.user_mapping_row import UserMappingRow\n",
    "from models.users.user_row import UserRow\n",
    "\n",
    "user_registry = UserRegistry(CSVLoader(UserRow).read(), CSVLoader(UserMappingRow).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ratings.rating_registry import RatingRegistry\n",
    "from models.ratings.rating_row import RatingRow\n",
    "\n",
    "rating_registry = RatingRegistry(CSVLoader(RatingRow).read(), user_registry, product_registry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_registry.ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting attributes from the Rating objects\n",
    "ratings_data = [\n",
    "    {\n",
    "        \"userid\": rating.user.uid,\n",
    "        \"gender\": rating.user.gender,\n",
    "        \"age\": rating.user.age,\n",
    "        \"productid\": rating.product.pid,\n",
    "        \"pname\": rating.product.name,\n",
    "        \"pgenre\": rating.product.genre,\n",
    "        \"rating\": rating.rating,\n",
    "        \"timestamp\": rating.timestamp\n",
    "    }\n",
    "    for rating in rating_registry.ratings\n",
    "]\n",
    "\n",
    "# Converting to DataFrame\n",
    "ratings = pd.DataFrame(ratings_data)\n",
    "\n",
    "# Displaying the first few rows of the DataFrame\n",
    "ratings.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"ratings_dataset.xlsx\"\n",
    "ratings.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Dataset successfully saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import pandas as pd\n",
    "ratings = pd.read_excel('ratings_dataset.xlsx') \"\"\"\n",
    "sample_df = ratings.sample(n=500, random_state=42)\n",
    "\n",
    "# Saving the sample DataFrame to an Excel file\n",
    "output_file = \"ratings_sample_dataset.xlsx\"\n",
    "sample_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Sample dataset successfully saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything is encoded in here and working. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate balanced partitions and generate progol program for each partiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def generate_balanced_partitions(file_path, output_dir, num_partitions, use_actor=False):\n",
    "    # Load the dataset\n",
    "    data = pd.read_excel(file_path)\n",
    "\n",
    "    # Define all possible categories for age, genres, and gender\n",
    "    possible_ages = {\n",
    "        \"Under 18\": \"under_18\",\n",
    "        \"18-24\": \"b18to24\",\n",
    "        \"25-34\": \"b25to34\",\n",
    "        \"35-44\": \"b35to44\",\n",
    "        \"45-49\": \"b45to49\",\n",
    "        \"50-55\": \"b50to55\",\n",
    "        \"56+\": \"plus56\"\n",
    "    }\n",
    "    \n",
    "    possible_genres = {\n",
    "        \"Action\": \"action\",\n",
    "        \"Adventure\": \"adventure\",\n",
    "        \"Animation\": \"animation\",\n",
    "        \"Children's\": \"childrens\",\n",
    "        \"Comedy\": \"comedy\",\n",
    "        \"Crime\": \"crime\",\n",
    "        \"Documentary\": \"documentary\",\n",
    "        \"Drama\": \"drama\",\n",
    "        \"Fantasy\": \"fantasy\",\n",
    "        \"Film-Noir\": \"filmnoir\",\n",
    "        \"Horror\": \"horror\",\n",
    "        \"Musical\": \"musical\",\n",
    "        \"Mystery\": \"mystery\",\n",
    "        \"Romance\": \"romance\",\n",
    "        \"Sci-Fi\": \"sci_fi\",\n",
    "        \"Thriller\": \"thriller\",\n",
    "        \"Western\": \"western\",\n",
    "        \"War\": \"war\"\n",
    "    }\n",
    "\n",
    "    possible_genders = [\"m\", \"f\"]\n",
    "\n",
    "    # Split the data into positive and negative examples\n",
    "    positive_data = data[data['rating'] > 3].copy()\n",
    "    negative_data = data[data['rating'] <= 3].copy()\n",
    "\n",
    "    # Shuffle the data\n",
    "    positive_data = positive_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    negative_data = negative_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Determine the size of each partition\n",
    "    pos_partition_size = len(positive_data) // num_partitions\n",
    "    neg_partition_size = len(negative_data) // num_partitions\n",
    "\n",
    "    # Ensure that the partitions are balanced\n",
    "    partitions = []\n",
    "    for i in range(num_partitions):\n",
    "        pos_start = i * pos_partition_size\n",
    "        pos_end = pos_start + pos_partition_size\n",
    "        neg_start = i * neg_partition_size\n",
    "        neg_end = neg_start + neg_partition_size\n",
    "\n",
    "        # Handle remainders by distributing them to the partitions\n",
    "        if i == num_partitions - 1:\n",
    "            pos_end = len(positive_data)\n",
    "            neg_end = len(negative_data)\n",
    "\n",
    "        partition = pd.concat([\n",
    "            positive_data.iloc[pos_start:pos_end],\n",
    "            negative_data.iloc[neg_start:neg_end]\n",
    "        ]).reset_index(drop=True)\n",
    "        \n",
    "        partitions.append(partition)\n",
    "\n",
    "    # Generate Prolog programs for each partition\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    for i, partition in enumerate(partitions):\n",
    "        output_file_name = f\"{output_dir}/prolog_program_partition_{i+1}\"\n",
    "        generate_progol_program_for_partition(partition, possible_ages, possible_genres, possible_genders, output_file_name, use_actors=use_actor)\n",
    "\n",
    "def generate_progol_program_for_partition(partition, possible_ages, possible_genres, possible_genders, output_file_name, use_actors=False):\n",
    "    mapping_dict_product_to_kg = {}\n",
    "    mapping_dict_kg_to_product = {}\n",
    "    with open(\"../results/ml1m/preprocessed/pgpr/mappings/product_mapping.txt\", \"r\") as file:\n",
    "        next(file)  # Skip the header\n",
    "        for line in file:\n",
    "            rating_id, new_id = line.strip().split(\"\\t\")\n",
    "            mapping_dict_kg_to_product[str(new_id)] = str(rating_id)\n",
    "            mapping_dict_product_to_kg[str(rating_id)] = str(new_id)\n",
    "            \n",
    "    # Prepare containers for Prolog facts\n",
    "    positive_examples = []\n",
    "    negative_examples = []\n",
    "    background_knowledge = set()\n",
    "\n",
    "    # Track the present predicates\n",
    "    present_ages = set()\n",
    "    present_genres = set()\n",
    "    present_genders = set()\n",
    "    if use_actors:\n",
    "        relations = pd.read_csv(\"../results/ml1m/preprocessed/kg_final.txt\", sep=\"\\t\", header=0)\n",
    "        movies_actors = relations[relations['relation']==4]\n",
    "        movies_directors = relations[relations['relation']==9]\n",
    "\n",
    "\n",
    "    # Process each row in the partition\n",
    "    for _, row in partition.iterrows():\n",
    "        user_id = f\"u{row['userid']}\"\n",
    "        movie_id = f\"m{row['productid']}\"\n",
    "        rating = row['rating']\n",
    "        age_group = possible_ages.get(row['age'], \"\").lower()  # Replace age group with corresponding Prolog predicate\n",
    "        gender = row['gender'].lower()  # Normalize gender\n",
    "        genre = possible_genres.get(row['pgenre'], \"\").lower()  # Replace genre with corresponding Prolog predicate\n",
    "\n",
    "        # Generate positive and negative examples\n",
    "        if rating > 3:\n",
    "            positive_examples.append(f\"recommend({user_id}, {movie_id}).\")\n",
    "        else:\n",
    "            negative_examples.append(f\"recommend({user_id}, {movie_id}).\")\n",
    "\n",
    "        # Background knowledge: user attributes\n",
    "        if age_group:\n",
    "            background_knowledge.add(f\"{age_group}({user_id}).\")\n",
    "            present_ages.add(age_group)\n",
    "        if gender in possible_genders:\n",
    "            background_knowledge.add(f\"{gender}({user_id}).\")\n",
    "            present_genders.add(gender)\n",
    "\n",
    "        # Background knowledge: movie genre\n",
    "        if genre:\n",
    "            background_knowledge.add(f\"{genre}({movie_id}).\")\n",
    "            present_genres.add(genre)\n",
    "        if use_actors:    \n",
    "            # Add the director and actor informations\n",
    "            movie_mapping = int(mapping_dict_product_to_kg[movie_id[1:]])\n",
    "            movies_actor = movies_actors[movies_actors['entity_head']==movie_mapping]['entity_tail']\n",
    "            for m_actor in movies_actor:\n",
    "                background_knowledge.add(f\"movie_actor({movie_id},a{m_actor}).\")\n",
    "    \n",
    "    # use a part of the recommendations as watched background knowledge\n",
    "    np.random.shuffle(positive_examples)\n",
    "    np.random.shuffle(negative_examples)\n",
    "    pos_l = len(positive_examples)\n",
    "    neg_l = len(negative_examples)\n",
    "    watched = positive_examples[:int(pos_l*0.5)] + negative_examples[:int(neg_l*0.5)]\n",
    "    positive_examples = positive_examples[int(pos_l*0.5):]\n",
    "    negative_examples = negative_examples[int(neg_l*0.5):]\n",
    "    watched = [m.replace('recommend','watched') for m in watched]\n",
    "    background_knowledge = background_knowledge.union(set(watched))\n",
    "    similar = [f\"similar(A,B):- watched(A,X), {genre}(X), {genre}(Y), watched(B,Y).\" for genre in present_genres]\n",
    "    similar += [\"similar(A,B):- watched(A,X), actor(X,Z), watched(B,Y), actor(Y,Z).\"]\n",
    "    share_insterest = \"share_interest(A,B):- similar(A,X), watched(X,B).\"\n",
    "    background_knowledge = background_knowledge.union(set(similar+[share_insterest]))\n",
    "\n",
    "    # Mode declarations\n",
    "    modeh_declaration = \"modeh(*, recommend(+user, +movie)).\"\n",
    "    modeb_declarations = [\n",
    "        f\"modeb(*, {age}(+user)).\" for age in present_ages\n",
    "    ] + [\n",
    "        f\"modeb(*, watched(+user, +movie)).\"\n",
    "    ] + [\n",
    "        f\"modeb(*, {gender}(+user)).\" for gender in present_genders\n",
    "    ] + [\n",
    "        f\"modeb(*, {genre}(+movie)).\" for genre in present_genres\n",
    "    ] + [\n",
    "        f\"modeb(*, similar(+user, +user)).\"\n",
    "    ]\n",
    "    if use_actors:\n",
    "        modeb_declarations.append(f\"modeb(*, movie_actor(+movie, -actor)).\")\n",
    "        modeb_declarations.append(f\"modeb(*, share_interest(+user, -movie)).\")\n",
    "    \n",
    "    modeb_declarations = [declaration for declaration in modeb_declarations if declaration]  # Remove empty strings\n",
    "\n",
    "    # Determinations\n",
    "    determinations = [\n",
    "        f\"determination(recommend/2, {age}/1).\" for age in present_ages\n",
    "    ] + [\n",
    "        f\"determination(recommend/2, watched/2).\"\n",
    "    ] + [\n",
    "        f\"determination(recommend/2, {gender}/1).\" for gender in present_genders\n",
    "    ] + [\n",
    "        f\"determination(recommend/2, {genre}/1).\" for genre in present_genres\n",
    "    ] + [\n",
    "        f\"determination(recommend/2, similar/2).\"\n",
    "    ]\n",
    "    if use_actors:\n",
    "        determinations.append(f\"determination(recommend/2, movie_actor/2).\")\n",
    "        determinations.append(f\"determination(recommend/2, share_interest/2).\")\n",
    "    \n",
    "    determinations = [determination for determination in determinations if determination]  # Remove empty strings\n",
    "\n",
    "    # Combine all parts into a Progol-compatible logic program\n",
    "    progol_program = \"% Mode Declarations\\n\"\n",
    "    progol_program += modeh_declaration + \"\\n\"\n",
    "    progol_program += \"\\n\".join(modeb_declarations) + \"\\n\\n\"\n",
    "\n",
    "    progol_program += \"% Determinations\\n\"\n",
    "    progol_program += \"\\n\".join(determinations) + \"\\n\\n\"\n",
    "\n",
    "    progol_program += \"% Background Knowledge\\n:- begin_bg.\\n\"\n",
    "    progol_program += \"\\n\".join(sorted(background_knowledge)) + \"\\n:- end_bg.\\n\\n\"\n",
    "\n",
    "    progol_program += \"% Positive Examples\\n:- begin_in_pos.\\n\"\n",
    "    progol_program += \"\\n\".join(positive_examples) + \"\\n:- end_in_pos.\\n\\n\"\n",
    "\n",
    "    progol_program += \"% Negative Examples\\n:- begin_in_neg.\\n\"\n",
    "    progol_program += \"\\n\".join(negative_examples) + \"\\n:- end_in_neg.\\n\"\n",
    "\n",
    "    # Save the Progol logic program to a file with a custom name\n",
    "    output_file_path = f\"{output_file_name}.pl\"\n",
    "    with open(output_file_path, \"w\") as file:\n",
    "        file.write(progol_program)\n",
    "\n",
    "    print(f\"Progol logic program saved as {output_file_path}\")\n",
    "\n",
    "# Usage example:\n",
    "num_partitions = 10\n",
    "use_actor = True\n",
    "ext = \"actors_\" if use_actor else ''\n",
    "file_path = 'ratings_sample_dataset.xlsx'  # Replace with your actual file path\n",
    "output_dir = '../prolog_partitions_'+ext+str(num_partitions)  # Directory to save the partitions\n",
    "generate_balanced_partitions(file_path, output_dir, num_partitions, use_actor=use_actor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause: recommend(A, B) :- f(A), comedy(B)., Coverage: {'positive_entailed': 2, 'positive_not_entailed': 12, 'negative_entailed': 0, 'negative_not_entailed': 11, 'score': 2, 'm_estimate': 0.6428571428571429}\n",
      "Clause: recommend(A, B) :- b18to24(A), f(A)., Coverage: {'positive_entailed': 2, 'positive_not_entailed': 12, 'negative_entailed': 0, 'negative_not_entailed': 11, 'score': 2, 'm_estimate': 0.6428571428571429}\n",
      "Clause: recommend(A, B) :- under_18(A)., Coverage: {'positive_entailed': 1, 'positive_not_entailed': 13, 'negative_entailed': 0, 'negative_not_entailed': 11, 'score': 1, 'm_estimate': 0.5833333333333334}\n",
      "Clause: recommend(A, B) :- b18to24(A), action(B)., Coverage: {'positive_entailed': 2, 'positive_not_entailed': 12, 'negative_entailed': 0, 'negative_not_entailed': 11, 'score': 2, 'm_estimate': 0.6428571428571429}\n",
      "Clause: recommend(A, B) :- filmnoir(B)., Coverage: {'positive_entailed': 1, 'positive_not_entailed': 13, 'negative_entailed': 0, 'negative_not_entailed': 11, 'score': 1, 'm_estimate': 0.5833333333333334}\n",
      "Total coverage: {'positive_entailed': 8, 'positive_not_entailed': 6, 'negative_entailed': 0, 'negative_not_entailed': 11, 'score': 8, 'm_estimate': 0.8076923076923077}\n"
     ]
    }
   ],
   "source": [
    "from andante.program import AndanteProgram \n",
    "from coverage import evaluate_clause_coverage\n",
    "apmovies = AndanteProgram.build_from(\"../prolog_partitions_actors_10/prolog_program_partition_5.pl\")\n",
    "background_knowledge = apmovies.knowledge.copy()\n",
    "H = apmovies.induce(update_knowledge=True, logging=True, verbose=0)\n",
    "H.clauses\n",
    "\n",
    "positive_examples =apmovies.examples['pos']\n",
    "negative_examples = apmovies.examples['neg']\n",
    "induced_clauses = H\n",
    "results = []\n",
    "for clause in induced_clauses:\n",
    "    coverage_score = evaluate_clause_coverage(clause, positive_examples, negative_examples, background_knowledge.copy())\n",
    "    results.append((clause, coverage_score))\n",
    "for clause, score in results:\n",
    "    print(f'Clause: {clause}, Coverage: {score}')\n",
    "total_coverage = evaluate_clause_coverage(next(induced_clauses.__iter__()), positive_examples, negative_examples, apmovies.knowledge.copy())\n",
    "print(f'Total coverage: {total_coverage}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query \n",
    "#### Lance une requête pour déterminer si B est recommendé à A en utilisant les règles et les faits définis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apmovies.query(\"recommend(A,B).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Test with Jhon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rule was satisfied for john. Movies recommended:\n",
      "     0      1      2      3\n",
      "X  m47  m2987  m1259  m1348\n"
     ]
    }
   ],
   "source": [
    "# Define new user and rule\n",
    "new_user = \"john\"  # Assume 'John' is the new user\n",
    "new_rule_for_user = f\"recommend({new_user}, X).\"  # Rule specific to the new user\n",
    "\n",
    "# Query the system\n",
    "success, substitutions = apmovies.query(new_rule_for_user)\n",
    "\n",
    "# Display result\n",
    "if success:\n",
    "    print(f\"The rule was satisfied for {new_user}. Movies recommended:\")\n",
    "    print(substitutions)\n",
    "else:\n",
    "    print(f\"No movie recommendations found for {new_user}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save and Load Model \n",
    "##### think about adding apmovies.results = inducedrules to force the save of the results before saving the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AndanteProgram saved to saved_andante_program.pkl\n",
      "Results from loaded program:\n",
      "Knowledge object (class: TreeShapedKnowledge)\n",
      "Clauses:\n",
      "   recommend(A, B) :- b45to49(A).\n",
      "   recommend(A, B) :- b18to24(A), drama(B).\n",
      "   recommend(A, B) :- crime(B).\n",
      "   recommend(A, B) :- horror(B).\n",
      "   recommend(A, B) :- b25to34(A), f(A).\n",
      "   recommend(A, B) :- adventure(B).\n",
      "Query successful. Substitutions found:\n",
      "          0      1      2      3      4      5      6      7      8      9   \\\n",
      "User   u3539  m2987  m1259  u2777  u2777  u2777  u2777  u2777  u2777  u1433   \n",
      "Movie  u3539  m2987  m1259  m1178  m1960    m17   m337  m1619   m924  m1178   \n",
      "\n",
      "       ...     38     39     40     41     42     43     44     45     46   47  \n",
      "User   ...  u4411  u1778  u1778  u1778  u1778  u1778  u1778  m1348  u5127  m47  \n",
      "Movie  ...   m924  m1178  m1960    m17   m337  m1619   m924  m1348  u5127  m47  \n",
      "\n",
      "[2 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "from andante.program import AndanteProgram \n",
    "\n",
    "# Generate or load an AndanteProgram instance\n",
    "apmovies = AndanteProgram.build_from(\"../prolog_partitions_six/prolog_program_partition_5.pl\")\n",
    "\n",
    "# Perform learning or querying as usual\n",
    "induced_hypotheses = apmovies.induce(update_knowledge=True, logging=True, verbose=0)\n",
    "\n",
    "# 1. Save the AndanteProgram instance\n",
    "apmovies.results = induced_hypotheses\n",
    "apmovies.save(\"saved_andante_program.pkl\")\n",
    "\n",
    "# 2. Load the AndanteProgram instance\n",
    "loaded_apmovies = AndanteProgram.load(\"saved_andante_program.pkl\")\n",
    "\n",
    "# 3. Access attributes such as `results`\n",
    "print(\"Results from loaded program:\")\n",
    "print(loaded_apmovies.results)\n",
    "\n",
    "# 4. Use the `query` method on the loaded program\n",
    "success, substitutions = loaded_apmovies.query(\"recommend(User, Movie).\")\n",
    "\n",
    "# 5. Display the query results\n",
    "if success:\n",
    "    print(\"Query successful. Substitutions found:\")\n",
    "    print(substitutions)\n",
    "else:\n",
    "    print(\"Query failed. No substitutions found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### il faut rajouter le nouveau user profile au Bk dans un programme Andante ---> le système ensuite doit regarder pour lui infèrer une recommendation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    ":- begin_bg.\n",
    "user(u777).\n",
    "b18to24(u777).\n",
    "f(u777).\n",
    "movie(m777).\n",
    "drama(m777).\n",
    "action(m1374).\n",
    "action(m1676).\n",
    "adventure(m1259).\n",
    "adventure(m2987).\n",
    "b18to24(u1433).\n",
    "b18to24(u1778).\n",
    "b18to24(u2777).\n",
    "b18to24(u3418).\n",
    "b18to24(u4103).\n",
    "b18to24(u4411).\n",
    "b18to24(u621).\n",
    "b25to34(u2840).\n",
    "b25to34(u3123).\n",
    "b25to34(u3539).\n",
    "b25to34(u4138).\n",
    "b25to34(u4560).\n",
    "b25to34(u4607).\n",
    "b25to34(u5077).\n",
    "b35to44(u1197).\n",
    "b45to49(u5127).\n",
    "b50to55(u4981).\n",
    "comedy(m19).\n",
    "comedy(m2596).\n",
    "comedy(m2888).\n",
    "comedy(m3909).\n",
    "comedy(m691).\n",
    "crime(m47).\n",
    "drama(m1178).\n",
    "drama(m1619).\n",
    "drama(m17).\n",
    "drama(m1960).\n",
    "drama(m337).\n",
    "drama(m924).\n",
    "f(u1433).\n",
    "f(u3418).\n",
    "f(u3539).\n",
    "horror(m1348).\n",
    "m(u1197).\n",
    "m(u1778).\n",
    "m(u2777).\n",
    "m(u2840).\n",
    "m(u3123).\n",
    "m(u4083).\n",
    "m(u4103).\n",
    "m(u4138).\n",
    "m(u4411).\n",
    "m(u4560).\n",
    "m(u4607).\n",
    "m(u4981).\n",
    "m(u5077).\n",
    "m(u5127).\n",
    "m(u621).\n",
    "plus56(u4083).\n",
    "sci_fi(m1206).\n",
    "recommend(A, B) :- b45to49(A).\n",
    "recommend(A, B) :- b18to24(A), drama(B).\n",
    "recommend(A, B) :- crime(B).\n",
    "recommend(A, B) :- horror(B).\n",
    "recommend(A, B) :- b25to34(A), f(A).\n",
    "recommend(A, B) :- adventure(B).\n",
    ":- end_bg.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add new user profile, rules to Bk - method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_user_profile_tobk(user_profile, loadedmovies):\n",
    "    \"\"\"\n",
    "    Generates the Prolog-style user profile and extracted rules from the loaded_apmovies results.\n",
    "\n",
    "    Parameters:\n",
    "    - user_profile (dict): A dictionary containing the user profile information (user_id, age_group, gender, movie_id, movie_genre, rating).\n",
    "    - loaded_apmovies_results (list of Clause): The list of induced rules (clauses) from loaded_apmovies.results.\n",
    "\n",
    "    Returns:\n",
    "    - str: A formatted string containing the user profile facts and the extracted rules in Prolog-style.\n",
    "    \"\"\"\n",
    "    # Extract user profile details from the input dictionary\n",
    "    user_id = user_profile.get(\"user_id\")\n",
    "    age_group = user_profile.get(\"age_group\")\n",
    "    gender = user_profile.get(\"gender\")\n",
    "    movie_id = user_profile.get(\"movie_id\")\n",
    "    movie_genre = user_profile.get(\"movie_genre\")\n",
    "    rating = user_profile.get(\"rating\")\n",
    "\n",
    "    # Start building the Prolog-style background knowledge text\n",
    "    text = \":- begin_bg.\\n\"\n",
    "\n",
    "    # Add user profile facts\n",
    "    text += f\"    user({user_id}).\\n\"\n",
    "    text += f\"    {age_group}({user_id}).\\n\"\n",
    "    text += f\"    {gender}({user_id}).\\n\"\n",
    "    text += f\"    movie({movie_id}).\\n\"\n",
    "    text += f\"    {movie_genre}({movie_id}).\\n\"\n",
    "    text += f\"    rating({rating}).\\n\"\n",
    "\n",
    "    # Add the extracted rules from the loaded_apmovies results\n",
    "    for rule in loadedmovies.results:\n",
    "        rule_str = str(rule)  # Convert the rule to a string (assuming rule is a Clause object)\n",
    "        text += f\"    {rule_str}\\n\"\n",
    "    \n",
    "    for bk in loadedmovies.knowledge:\n",
    "        bk_str = str(bk)\n",
    "        text+= f\"{bk_str}\\n\"\n",
    "\n",
    "    # End the background knowledge\n",
    "    text += \":- end_bg.\\n\"\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define user profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test with user profile\n",
    "user_profile = {\n",
    "    \"user_id\": \"u777\",\n",
    "    \"age_group\": \"b18to24\",  # Age group: 18-24\n",
    "    \"gender\": \"f\",  # Gender: Male\n",
    "    \"movie_id\": \"m777\",\n",
    "    \"movie_genre\": \"drama\",\n",
    "    \"rating\": 4\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add user profile to Bk, add rules to Bk ( Bk recuperated from loaded model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved AndanteProgram instance\n",
    "loaded_apmovies = AndanteProgram.load(\"saved_andante_program.pkl\")\n",
    "\n",
    "#Extract rules from loaded_apmovies and add it to user profile\n",
    "user_background_profile = add_user_profile_tobk(user_profile, loaded_apmovies)\n",
    "\n",
    "# Define a query for the new user 'u777' based on induced clauses\n",
    "#new_user_id = \"u777\"  # New user ID\n",
    "user_id = user_profile[\"user_id\"]\n",
    "query_rule_for_user = f\"recommend({user_id}, X).\"  # Query for movie recommendations\n",
    "\n",
    "# Query the system using the induced clauses to get recommendations for the new user\n",
    "success, substitutions = loaded_apmovies.query(query_rule_for_user)\n",
    "\n",
    "# Display result using the induced clauses\n",
    "if success:\n",
    "    print(f\"The rule was satisfied for {user_id}. Movies recommended:\")\n",
    "    print(substitutions)\n",
    "else:\n",
    "    print(f\"No movie recommendations found for {new_user}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_background_profile = add_user_profile_tobk(user_profile, loaded_apmovies)\n",
    "#print(user_background_profile)\n",
    "#extract user id \n",
    "user_id = user_profile[\"user_id\"]\n",
    "query_rule_for_user = f\"recommend({user_id}, X).\"\n",
    "\n",
    "ap2 = AndanteProgram.build_from(user_background_profile)\n",
    "ap2.results = loaded_apmovies.results\n",
    "ap2.query(query_rule_for_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommandations trouvées :\n",
      "    0      1      2      3      4    5     6      7     8     9      10\n",
      "X  m47  m2987  m1259  m1178  m1960  m17  m337  m1619  m777  m924  m1348\n",
      "Explication des règles activées :\n",
      "Matched rule(s): recommend(A, B) :- b45to49(A)., recommend(A, B) :- b18to24(A), drama(B)., recommend(A, B) :- crime(B)., recommend(A, B) :- horror(B)., recommend(A, B) :- b25to34(A), f(A)., recommend(A, B) :- adventure(B).\n",
      "Matched rule(s): recommend(A, B) :- b45to49(A)., recommend(A, B) :- b18to24(A), drama(B)., recommend(A, B) :- crime(B)., recommend(A, B) :- horror(B)., recommend(A, B) :- b25to34(A), f(A)., recommend(A, B) :- adventure(B).\n",
      "Matched rule(s): recommend(A, B) :- b45to49(A)., recommend(A, B) :- b18to24(A), drama(B)., recommend(A, B) :- crime(B)., recommend(A, B) :- horror(B)., recommend(A, B) :- b25to34(A), f(A)., recommend(A, B) :- adventure(B).\n",
      "Matched rule(s): recommend(A, B) :- b45to49(A)., recommend(A, B) :- b18to24(A), drama(B)., recommend(A, B) :- crime(B)., recommend(A, B) :- horror(B)., recommend(A, B) :- b25to34(A), f(A)., recommend(A, B) :- adventure(B).\n",
      "Matched rule(s): recommend(A, B) :- b45to49(A)., recommend(A, B) :- b18to24(A), drama(B)., recommend(A, B) :- crime(B)., recommend(A, B) :- horror(B)., recommend(A, B) :- b25to34(A), f(A)., recommend(A, B) :- adventure(B).\n",
      "Matched rule(s): recommend(A, B) :- b45to49(A)., recommend(A, B) :- b18to24(A), drama(B)., recommend(A, B) :- crime(B)., recommend(A, B) :- horror(B)., recommend(A, B) :- b25to34(A), f(A)., recommend(A, B) :- adventure(B).\n",
      "Matched rule(s): recommend(A, B) :- b45to49(A)., recommend(A, B) :- b18to24(A), drama(B)., recommend(A, B) :- crime(B)., recommend(A, B) :- horror(B)., recommend(A, B) :- b25to34(A), f(A)., recommend(A, B) :- adventure(B).\n",
      "Matched rule(s): recommend(A, B) :- b45to49(A)., recommend(A, B) :- b18to24(A), drama(B)., recommend(A, B) :- crime(B)., recommend(A, B) :- horror(B)., recommend(A, B) :- b25to34(A), f(A)., recommend(A, B) :- adventure(B).\n",
      "Matched rule(s): recommend(A, B) :- b45to49(A)., recommend(A, B) :- b18to24(A), drama(B)., recommend(A, B) :- crime(B)., recommend(A, B) :- horror(B)., recommend(A, B) :- b25to34(A), f(A)., recommend(A, B) :- adventure(B).\n",
      "Matched rule(s): recommend(A, B) :- b45to49(A)., recommend(A, B) :- b18to24(A), drama(B)., recommend(A, B) :- crime(B)., recommend(A, B) :- horror(B)., recommend(A, B) :- b25to34(A), f(A)., recommend(A, B) :- adventure(B).\n",
      "Matched rule(s): recommend(A, B) :- b45to49(A)., recommend(A, B) :- b18to24(A), drama(B)., recommend(A, B) :- crime(B)., recommend(A, B) :- horror(B)., recommend(A, B) :- b25to34(A), f(A)., recommend(A, B) :- adventure(B).\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine rules from different partitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing prolog_partitions_six/prolog_program_partition_1.pl...\n",
      "Processing prolog_partitions_six/prolog_program_partition_2.pl...\n",
      "Processing prolog_partitions_six/prolog_program_partition_3.pl...\n",
      "Processing prolog_partitions_six/prolog_program_partition_4.pl...\n",
      "Processing prolog_partitions_six/prolog_program_partition_5.pl...\n",
      "Processing prolog_partitions_six/prolog_program_partition_6.pl...\n",
      "recommend(A, B) :- b25to34(A), comedy(B).\n",
      "recommend(A, B) :- crime(B).\n",
      "recommend(A, B) :- f(A).\n",
      "recommend(A, B) :- b25to34(A), action(B).\n",
      "recommend(A, B) :- b45to49(A).\n",
      "recommend(A, B) :- b18to24(A), drama(B).\n",
      "recommend(A, B) :- horror(B).\n",
      "recommend(A, B) :- b25to34(A), f(A).\n",
      "recommend(A, B) :- adventure(B).\n",
      "recommend(A, B) :- m(A), drama(B).\n",
      "Combined rules saved to combined_rules.txt\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from andante.program import AndanteProgram\n",
    "from andante.collections import OrderedSet\n",
    "from andante.logic_concepts import Clause\n",
    "\n",
    "from andante.knowledge import TreeShapedKnowledge\n",
    "# Define the directory containing the Prolog partition files\n",
    "prolog_directory = \"prolog_partitions_six\"\n",
    "\n",
    "# List of partition file names\n",
    "partition_files = [\n",
    "    f\"{prolog_directory}/prolog_program_partition_{i+1}.pl\"\n",
    "    for i in range(6)  # Assuming 6 partitions, adjust as needed\n",
    "]\n",
    "\n",
    "# Initialize an OrderedSet to hold all unique rules\n",
    "all_rules = OrderedSet()\n",
    "\n",
    "# Iterate over each partition file and induce rules\n",
    "for partition_file in partition_files:\n",
    "    print(f\"Processing {partition_file}...\")\n",
    "    # Build the AndanteProgram from the current partition file\n",
    "    ap = AndanteProgram.build_from(partition_file)\n",
    "    \n",
    "    # Induce rules and update knowledge\n",
    "    induced_knowledge = ap.induce(update_knowledge=True, logging=True, verbose=0)\n",
    "    \n",
    "    # If induced_knowledge is a TreeShapedKnowledge, extract its clauses\n",
    "    if isinstance(induced_knowledge, TreeShapedKnowledge):\n",
    "        for clause in induced_knowledge.clauses:\n",
    "            if isinstance(clause, Clause):\n",
    "                all_rules.add(clause)\n",
    "    else:\n",
    "        print(f\"Unexpected type for induced_rules: {type(induced_knowledge)}\")\n",
    "\n",
    "# Output the combined rules\n",
    "for rule in all_rules:\n",
    "    print(rule)\n",
    "\n",
    "# Optionally, save the combined rules to a file\n",
    "with open(\"combined_rules.txt\", \"w\") as f:\n",
    "    for rule in all_rules:\n",
    "        f.write(str(rule) + \"\\n\")\n",
    "\n",
    "print(\"Combined rules saved to combined_rules.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Union with normalization and unification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from andante.program import AndanteProgram\n",
    "from andante.collections import OrderedSet\n",
    "from andante.logic_concepts import Clause, Atom, Variable, Predicate\n",
    "from andante.knowledge import TreeShapedKnowledge\n",
    "\n",
    "# Define the directory containing the Prolog partition files\n",
    "prolog_directory = \"prolog_partitions_six\"\n",
    "\n",
    "# List of partition file names\n",
    "partition_files = [\n",
    "    f\"{prolog_directory}/prolog_program_partition_{i+1}.pl\"\n",
    "    for i in range(6)  # Assuming 6 partitions, adjust as needed\n",
    "]\n",
    "\n",
    "# Initialize an OrderedSet to hold all unique rules\n",
    "all_rules = OrderedSet()\n",
    "\n",
    "# Function to normalize and unify clauses\n",
    "def normalize_clause(clause):\n",
    "    # Sort the literals in the body of the clause for consistent ordering\n",
    "    sorted_body = sorted(clause.body, key=lambda atom: str(atom))\n",
    "\n",
    "    # Standardize variable names: use a consistent naming scheme, e.g., A, B, C...\n",
    "    var_mapping = {}\n",
    "    new_body = []\n",
    "    new_head = clause.head\n",
    "\n",
    "    for atom in sorted_body:\n",
    "        new_terms = []\n",
    "        for term in atom:\n",
    "            if isinstance(term, Variable):\n",
    "                if term not in var_mapping:\n",
    "                    var_mapping[term] = Variable(chr(ord('A') + len(var_mapping)))\n",
    "                new_terms.append(var_mapping[term])\n",
    "            else:\n",
    "                new_terms.append(term)\n",
    "        new_body.append(Atom(atom.predicate, new_terms))\n",
    "\n",
    "    # Apply the same mapping to the head of the clause\n",
    "    if clause.head:\n",
    "        new_head_terms = []\n",
    "        for term in clause.head.terms:\n",
    "            if isinstance(term, Variable):\n",
    "                new_head_terms.append(var_mapping.get(term, term))\n",
    "            else:\n",
    "                new_head_terms.append(term)\n",
    "        new_head = Atom(clause.head.predicate, new_head_terms)\n",
    "\n",
    "    # Return the normalized clause\n",
    "    return Clause(new_head, new_body)\n",
    "\n",
    "# Iterate over each partition file and induce rules\n",
    "for partition_file in partition_files:\n",
    "    print(f\"Processing {partition_file}...\")\n",
    "    # Build the AndanteProgram from the current partition file\n",
    "    ap = AndanteProgram.build_from(partition_file)\n",
    "    \n",
    "    # Induce rules and update knowledge\n",
    "    induced_knowledge = ap.induce(update_knowledge=True, logging=True, verbose=0)\n",
    "    \n",
    "    # If induced_knowledge is a TreeShapedKnowledge, extract its clauses\n",
    "    if isinstance(induced_knowledge, TreeShapedKnowledge):\n",
    "        for clause in induced_knowledge.clauses:\n",
    "            if isinstance(clause, Clause):\n",
    "                normalized_clause = normalize_clause(clause)\n",
    "                all_rules.add(normalized_clause)\n",
    "    else:\n",
    "        print(f\"Unexpected type for induced_rules: {type(induced_knowledge)}\")\n",
    "\n",
    "# Function to check for redundancy and remove duplicates\n",
    "def remove_redundancy(rules):\n",
    "    unique_rules = OrderedSet()\n",
    "    for rule in rules:\n",
    "        if rule not in unique_rules:\n",
    "            unique_rules.add(rule)\n",
    "    return unique_rules\n",
    "\n",
    "# Remove redundancy from all_rules\n",
    "all_rules = remove_redundancy(all_rules)\n",
    "\n",
    "# Output the combined, normalized, and unique rules\n",
    "for rule in all_rules:\n",
    "    print(rule)\n",
    "\n",
    "# Optionally, save the combined rules to a file\n",
    "with open(\"combined_rules.txt\", \"w\") as f:\n",
    "    for rule in all_rules:\n",
    "        f.write(str(rule) + \"\\n\")\n",
    "\n",
    "print(\"Combined, normalized, and unique rules saved to combined_rules_normalized.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
