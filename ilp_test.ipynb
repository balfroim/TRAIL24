{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.csv_loader import CSVLoader\n",
    "from models.products.product_registry import ProductRegistry\n",
    "from models.products.product_mapping_row import ProductMappingRow\n",
    "from models.products.product_row import ProductRow\n",
    "\n",
    "product_registry = ProductRegistry(CSVLoader(ProductRow).read(), CSVLoader(ProductMappingRow).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.users.user_registry import UserRegistry\n",
    "from models.users.user_mapping_row import UserMappingRow\n",
    "from models.users.user_row import UserRow\n",
    "\n",
    "user_registry = UserRegistry(CSVLoader(UserRow).read(), CSVLoader(UserMappingRow).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ratings.rating_registry import RatingRegistry\n",
    "from models.ratings.rating_row import RatingRow\n",
    "\n",
    "rating_registry = RatingRegistry(CSVLoader(RatingRow).read(), user_registry, product_registry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_registry.ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>productid</th>\n",
       "      <th>pname</th>\n",
       "      <th>pgenre</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>Under 18</td>\n",
       "      <td>1193</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>Under 18</td>\n",
       "      <td>661</td>\n",
       "      <td>James and the Giant Peach (1996)</td>\n",
       "      <td>Animation</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>Under 18</td>\n",
       "      <td>914</td>\n",
       "      <td>My Fair Lady (1964)</td>\n",
       "      <td>Musical</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>Under 18</td>\n",
       "      <td>3408</td>\n",
       "      <td>Erin Brockovich (2000)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>Under 18</td>\n",
       "      <td>2355</td>\n",
       "      <td>Bug's Life, A (1998)</td>\n",
       "      <td>Animation</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid gender       age  productid                                   pname  \\\n",
       "0       1      F  Under 18       1193  One Flew Over the Cuckoo's Nest (1975)   \n",
       "1       1      F  Under 18        661        James and the Giant Peach (1996)   \n",
       "2       1      F  Under 18        914                     My Fair Lady (1964)   \n",
       "3       1      F  Under 18       3408                  Erin Brockovich (2000)   \n",
       "4       1      F  Under 18       2355                    Bug's Life, A (1998)   \n",
       "\n",
       "      pgenre  rating  timestamp  \n",
       "0      Drama       5  978300760  \n",
       "1  Animation       3  978302109  \n",
       "2    Musical       3  978301968  \n",
       "3      Drama       4  978300275  \n",
       "4  Animation       5  978824291  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting attributes from the Rating objects\n",
    "ratings_data = [\n",
    "    {\n",
    "        \"userid\": rating.user.uid,\n",
    "        \"gender\": rating.user.gender,\n",
    "        \"age\": rating.user.age,\n",
    "        \"productid\": rating.product.pid,\n",
    "        \"pname\": rating.product.name,\n",
    "        \"pgenre\": rating.product.genre,\n",
    "        \"rating\": rating.rating,\n",
    "        \"timestamp\": rating.timestamp\n",
    "    }\n",
    "    for rating in rating_registry.ratings\n",
    "]\n",
    "\n",
    "# Converting to DataFrame\n",
    "ratings = pd.DataFrame(ratings_data)\n",
    "\n",
    "# Displaying the first few rows of the DataFrame\n",
    "ratings.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully saved to ratings_dataset.xlsx\n"
     ]
    }
   ],
   "source": [
    "output_file = \"ratings_dataset.xlsx\"\n",
    "ratings.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Dataset successfully saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(932293, 8)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample dataset successfully saved to ratings_sample_dataset.xlsx\n"
     ]
    }
   ],
   "source": [
    "sample_df = ratings.sample(n=118, random_state=42)\n",
    "\n",
    "# Saving the sample DataFrame to an Excel file\n",
    "output_file = \"ratings_sample_dataset.xlsx\"\n",
    "sample_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Sample dataset successfully saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything is encoded in here and working. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate balanced partitions and generate progol program for each partiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progol logic program saved as ./prolog_partitions_six/prolog_program_partition_1.pl\n",
      "Progol logic program saved as ./prolog_partitions_six/prolog_program_partition_2.pl\n",
      "Progol logic program saved as ./prolog_partitions_six/prolog_program_partition_3.pl\n",
      "Progol logic program saved as ./prolog_partitions_six/prolog_program_partition_4.pl\n",
      "Progol logic program saved as ./prolog_partitions_six/prolog_program_partition_5.pl\n",
      "Progol logic program saved as ./prolog_partitions_six/prolog_program_partition_6.pl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def generate_balanced_partitions(file_path, output_dir):\n",
    "    # Load the dataset\n",
    "    data = pd.read_excel(file_path)\n",
    "\n",
    "    # Define all possible categories for age, genres, and gender\n",
    "    possible_ages = {\n",
    "        \"Under 18\": \"under_18\",\n",
    "        \"18-24\": \"b18to24\",\n",
    "        \"25-34\": \"b25to34\",\n",
    "        \"35-44\": \"b35to44\",\n",
    "        \"45-49\": \"b45to49\",\n",
    "        \"50-55\": \"b50to55\",\n",
    "        \"56+\": \"plus56\"\n",
    "    }\n",
    "    \n",
    "    possible_genres = {\n",
    "        \"Action\": \"action\",\n",
    "        \"Adventure\": \"adventure\",\n",
    "        \"Animation\": \"animation\",\n",
    "        \"Children's\": \"childrens\",\n",
    "        \"Comedy\": \"comedy\",\n",
    "        \"Crime\": \"crime\",\n",
    "        \"Documentary\": \"documentary\",\n",
    "        \"Drama\": \"drama\",\n",
    "        \"Fantasy\": \"fantasy\",\n",
    "        \"Film-Noir\": \"filmnoir\",\n",
    "        \"Horror\": \"horror\",\n",
    "        \"Musical\": \"musical\",\n",
    "        \"Mystery\": \"mystery\",\n",
    "        \"Romance\": \"romance\",\n",
    "        \"Sci-Fi\": \"sci_fi\",\n",
    "        \"Thriller\": \"thriller\",\n",
    "        \"Western\": \"western\",\n",
    "        \"War\": \"war\"\n",
    "    }\n",
    "\n",
    "    possible_genders = [\"m\", \"f\"]\n",
    "\n",
    "    # Split the data into positive and negative examples\n",
    "    positive_data = data[data['rating'] > 3].copy()\n",
    "    negative_data = data[data['rating'] <= 3].copy()\n",
    "\n",
    "    # Shuffle the data\n",
    "    positive_data = positive_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    negative_data = negative_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Determine the size of each partition\n",
    "    num_partitions = 6\n",
    "    pos_partition_size = len(positive_data) // num_partitions\n",
    "    neg_partition_size = len(negative_data) // num_partitions\n",
    "\n",
    "    # Ensure that the partitions are balanced\n",
    "    partitions = []\n",
    "    for i in range(num_partitions):\n",
    "        pos_start = i * pos_partition_size\n",
    "        pos_end = pos_start + pos_partition_size\n",
    "        neg_start = i * neg_partition_size\n",
    "        neg_end = neg_start + neg_partition_size\n",
    "\n",
    "        # Handle remainders by distributing them to the partitions\n",
    "        if i == num_partitions - 1:\n",
    "            pos_end = len(positive_data)\n",
    "            neg_end = len(negative_data)\n",
    "\n",
    "        partition = pd.concat([\n",
    "            positive_data.iloc[pos_start:pos_end],\n",
    "            negative_data.iloc[neg_start:neg_end]\n",
    "        ]).reset_index(drop=True)\n",
    "        \n",
    "        partitions.append(partition)\n",
    "\n",
    "    # Generate Prolog programs for each partition\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    for i, partition in enumerate(partitions):\n",
    "        output_file_name = f\"{output_dir}/prolog_program_partition_{i+1}\"\n",
    "        generate_progol_program_for_partition(partition, possible_ages, possible_genres, possible_genders, output_file_name)\n",
    "\n",
    "def generate_progol_program_for_partition(partition, possible_ages, possible_genres, possible_genders, output_file_name):\n",
    "    # Prepare containers for Prolog facts\n",
    "    positive_examples = []\n",
    "    negative_examples = []\n",
    "    background_knowledge = set()\n",
    "\n",
    "    # Track the present predicates\n",
    "    present_ages = set()\n",
    "    present_genres = set()\n",
    "    present_genders = set()\n",
    "\n",
    "    # Process each row in the partition\n",
    "    for _, row in partition.iterrows():\n",
    "        user_id = f\"u{row['userid']}\"\n",
    "        movie_id = f\"m{row['productid']}\"\n",
    "        rating = row['rating']\n",
    "        age_group = possible_ages.get(row['age'], \"\").lower()  # Replace age group with corresponding Prolog predicate\n",
    "        gender = row['gender'].lower()  # Normalize gender\n",
    "        genre = possible_genres.get(row['pgenre'], \"\").lower()  # Replace genre with corresponding Prolog predicate\n",
    "\n",
    "        # Generate positive and negative examples\n",
    "        if rating > 3:\n",
    "            positive_examples.append(f\"recommend({user_id}, {movie_id}).\")\n",
    "        else:\n",
    "            negative_examples.append(f\"recommend({user_id}, {movie_id}).\")\n",
    "\n",
    "        # Background knowledge: user attributes\n",
    "        if age_group:\n",
    "            background_knowledge.add(f\"{age_group}({user_id}).\")\n",
    "            present_ages.add(age_group)\n",
    "        if gender in possible_genders:\n",
    "            background_knowledge.add(f\"{gender}({user_id}).\")\n",
    "            present_genders.add(gender)\n",
    "\n",
    "        # Background knowledge: movie genre\n",
    "        if genre:\n",
    "            background_knowledge.add(f\"{genre}({movie_id}).\")\n",
    "            present_genres.add(genre)\n",
    "\n",
    "    # Mode declarations\n",
    "    modeh_declaration = \"modeh(*, recommend(+user, +movie)).\"\n",
    "    modeb_declarations = [\n",
    "        f\"modeb(*, {age}(+user)).\" for age in present_ages\n",
    "    ] + [\n",
    "        f\"modeb(*, {gender}(+user)).\" for gender in present_genders\n",
    "    ] + [\n",
    "        f\"modeb(*, {genre}(+movie)).\" for genre in present_genres\n",
    "    ]\n",
    "    modeb_declarations = [declaration for declaration in modeb_declarations if declaration]  # Remove empty strings\n",
    "\n",
    "    # Determinations\n",
    "    determinations = [\n",
    "        f\"determination(recommend/2, {age}/1).\" for age in present_ages\n",
    "    ] + [\n",
    "        f\"determination(recommend/2, {gender}/1).\" for gender in present_genders\n",
    "    ] + [\n",
    "        f\"determination(recommend/2, {genre}/1).\" for genre in present_genres\n",
    "    ]\n",
    "    determinations = [determination for determination in determinations if determination]  # Remove empty strings\n",
    "\n",
    "    # Combine all parts into a Progol-compatible logic program\n",
    "    progol_program = \"% Mode Declarations\\n\"\n",
    "    progol_program += modeh_declaration + \"\\n\"\n",
    "    progol_program += \"\\n\".join(modeb_declarations) + \"\\n\\n\"\n",
    "\n",
    "    progol_program += \"% Determinations\\n\"\n",
    "    progol_program += \"\\n\".join(determinations) + \"\\n\\n\"\n",
    "\n",
    "    progol_program += \"% Background Knowledge\\n:- begin_bg.\\n\"\n",
    "    progol_program += \"\\n\".join(sorted(background_knowledge)) + \"\\n:- end_bg.\\n\\n\"\n",
    "\n",
    "    progol_program += \"% Positive Examples\\n:- begin_in_pos.\\n\"\n",
    "    progol_program += \"\\n\".join(positive_examples) + \"\\n:- end_in_pos.\\n\\n\"\n",
    "\n",
    "    progol_program += \"% Negative Examples\\n:- begin_in_neg.\\n\"\n",
    "    progol_program += \"\\n\".join(negative_examples) + \"\\n:- end_in_neg.\\n\"\n",
    "\n",
    "    # Save the Progol logic program to a file with a custom name\n",
    "    output_file_path = f\"{output_file_name}.pl\"\n",
    "    with open(output_file_path, \"w\") as file:\n",
    "        file.write(progol_program)\n",
    "\n",
    "    print(f\"Progol logic program saved as {output_file_path}\")\n",
    "\n",
    "# Usage example:\n",
    "file_path = 'ratings_sample_dataset.xlsx'  # Replace with your actual file path\n",
    "output_dir = './prolog_partitions_six'  # Directory to save the partitions\n",
    "generate_balanced_partitions(file_path, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedSet([recommend(A, B) :- b45to49(A)., recommend(A, B) :- b18to24(A), drama(B)., recommend(A, B) :- crime(B)., recommend(A, B) :- horror(B)., recommend(A, B) :- b25to34(A), f(A)., recommend(A, B) :- adventure(B).])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from andante.program import AndanteProgram \n",
    "apmovies = AndanteProgram.build_from(\"prolog_partitions_six/prolog_program_partition_5.pl\")\n",
    "H = apmovies.induce(update_knowledge=True, logging=True, verbose=0)\n",
    "H.clauses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query \n",
    "#### Lance une requête pour déterminer si B est recommendé à A en utilisant les règles et les faits définis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       "       0    1      2      3      4      5      6      7      8      9   ...  \\\n",
       " B  m1348  m47  m2987  m1259  u3539  u5127  u4103  u4103  u4103  u4103  ...   \n",
       " A  m1348  m47  m2987  m1259  u3539  u5127    m17   m924  m1960   m337  ...   \n",
       " \n",
       "       38    39     40     41     42     43     44     45     46     47  \n",
       " B   u621  u621   u621   u621  u2777  u2777  u2777  u2777  u2777  u2777  \n",
       " A  m1960  m337  m1178  m1619    m17   m924  m1960   m337  m1178  m1619  \n",
       " \n",
       " [2 rows x 48 columns])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apmovies.query(\"recommend(A,B).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test with new user "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'utilisateur u777 existe déjà dans le programme.\n"
     ]
    }
   ],
   "source": [
    "def add_new_user_to_existing_program(file_path, new_user_id, new_user_age, new_user_gender, new_movie_id, user_movie_genre, rating_movie):\n",
    "    # Lire le fichier existant\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Vérifier si l'utilisateur existe déjà dans le fichier\n",
    "    user_exists = any(f\"{new_user_id}\" in line for line in lines)\n",
    "\n",
    "    if user_exists:\n",
    "        print(f\"L'utilisateur {new_user_id} existe déjà dans le programme.\")\n",
    "        return\n",
    "\n",
    "    # Variables pour garder les lignes modifiées\n",
    "    new_lines = []\n",
    "    bg_inserted = False\n",
    "    pos_inserted = False\n",
    "    neg_inserted = False\n",
    "\n",
    "    for line in lines:\n",
    "        # Ajouter les nouvelles données dans la bonne section\n",
    "        if \":- end_bg.\" in line and not bg_inserted:\n",
    "            # Ajouter les nouvelles données de background knowledge avant la fin de la section bg\n",
    "            new_lines.append(f\"{new_user_age}({new_user_id}).\\n\")\n",
    "            new_lines.append(f\"{new_user_gender}({new_user_id}).\\n\")\n",
    "            new_lines.append(f\"{user_movie_genre}({new_movie_id}).\\n\")\n",
    "            bg_inserted = True\n",
    "\n",
    "        if \":- end_in_pos.\" in line and not pos_inserted and rating_movie > 3:\n",
    "            # Ajouter la recommandation positive si le rating est > 3 avant la fin de la section pos\n",
    "            new_lines.append(f\"recommend({new_user_id}, {new_movie_id}).\\n\")\n",
    "            pos_inserted = True\n",
    "\n",
    "        if \":- end_in_neg.\" in line and not neg_inserted and rating_movie <= 3:\n",
    "            # Ajouter la recommandation négative si le rating est <= 3 avant la fin de la section neg\n",
    "            new_lines.append(f\"recommend({new_user_id}, {new_movie_id}).\\n\")\n",
    "            neg_inserted = True\n",
    "\n",
    "        # Ajouter la ligne originale\n",
    "        new_lines.append(line)\n",
    "\n",
    "    # Sauvegarder les modifications dans le fichier\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.writelines(new_lines)\n",
    "    \n",
    "    print(f\"Le programme logique a été mis à jour et sauvegardé dans {file_path}\")\n",
    "\n",
    "# Exemple d'utilisation\n",
    "file_path = 'prolog_partitions_six/prolog_program_partition_5.pl'\n",
    "\n",
    "new_user_id = \"u777\"\n",
    "new_user_age = \"b25to34\"  # Groupe d'âge: 25-34\n",
    "new_user_gender = \"m\"  # Sexe: Masculin\n",
    "new_movie_id = \"m777\"\n",
    "user_movie_genre = \"action\"\n",
    "rating_movie = 4\n",
    "\n",
    "add_new_user_to_existing_program(file_path, new_user_id, new_user_age, new_user_gender, new_movie_id, user_movie_genre, rating_movie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'utilisateur u777 existe déjà dans le programme.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\-'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\='\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\='\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\='\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "h 0\n",
      "Atom recommend(u777, Movie)\n",
      "Candidates {recommend(A, B) :- crime(B)., recommend(A, B) :- adventure(B)., recommend(A, B) :- b18to24(A), drama(B)., recommend(A, B) :- b25to34(A), f(A)., recommend(A, B) :- b45to49(A)., recommend(A, B) :- horror(B).}\n",
      "Match {recommend(A, B) :- crime(B)., recommend(A, B) :- adventure(B)., recommend(A, B) :- b18to24(A), drama(B)., recommend(A, B) :- b25to34(A), f(A)., recommend(A, B) :- b45to49(A)., recommend(A, B) :- horror(B).}\n",
      "Clause recommend(A, B) :- crime(B).\n",
      "Substitution {A: u777, B: Movie}\n",
      "Atoms [crime(Movie)]\n",
      "\n",
      "h 1\n",
      "Atom crime(Movie)\n",
      "Candidates {crime(m47).}\n",
      "Match {crime(m47).}\n",
      "Clause crime(m47).\n",
      "Substitution {A: u777, B: m47, Movie: m47}\n",
      "Atoms []\n",
      "\n",
      "h 2\n",
      "Atom recommend(u777, Movie)\n",
      "Clause recommend(A, B) :- adventure(B).\n",
      "Substitution {A: u777, B: Movie}\n",
      "Atoms [adventure(Movie)]\n",
      "\n",
      "h 3\n",
      "Atom adventure(Movie)\n",
      "Candidates {adventure(m2987)., adventure(m1259).}\n",
      "Match {adventure(m2987)., adventure(m1259).}\n",
      "Clause adventure(m2987).\n",
      "Substitution {A: u777, B: m2987, Movie: m2987}\n",
      "Atoms []\n",
      "\n",
      "h 4\n",
      "Atom adventure(Movie)\n",
      "Clause adventure(m1259).\n",
      "Substitution {A: u777, B: m1259, Movie: m1259}\n",
      "Atoms []\n",
      "\n",
      "h 5\n",
      "Atom recommend(u777, Movie)\n",
      "Clause recommend(A, B) :- b18to24(A), drama(B).\n",
      "Substitution {A: u777, B: Movie}\n",
      "Atoms [drama(Movie), b18to24(u777)]\n",
      "\n",
      "h 6\n",
      "Atom b18to24(u777)\n",
      "Candidates set()\n",
      "\n",
      "h 6\n",
      "Atom recommend(u777, Movie)\n",
      "Clause recommend(A, B) :- b25to34(A), f(A).\n",
      "Substitution {A: u777, B: Movie}\n",
      "Atoms [f(u777), b25to34(u777)]\n",
      "\n",
      "h 7\n",
      "Atom b25to34(u777)\n",
      "Candidates {b25to34(u777).}\n",
      "Match {b25to34(u777).}\n",
      "Clause b25to34(u777).\n",
      "Substitution {A: u777, B: Movie}\n",
      "Atoms [f(u777)]\n",
      "\n",
      "h 8\n",
      "Atom f(u777)\n",
      "Candidates set()\n",
      "\n",
      "h 8\n",
      "Atom recommend(u777, Movie)\n",
      "Clause recommend(A, B) :- b45to49(A).\n",
      "Substitution {A: u777, B: Movie}\n",
      "Atoms [b45to49(u777)]\n",
      "\n",
      "h 9\n",
      "Atom b45to49(u777)\n",
      "Candidates set()\n",
      "\n",
      "h 9\n",
      "Atom recommend(u777, Movie)\n",
      "Clause recommend(A, B) :- horror(B).\n",
      "Substitution {A: u777, B: Movie}\n",
      "Atoms [horror(Movie)]\n",
      "\n",
      "h 10\n",
      "Atom horror(Movie)\n",
      "Candidates {horror(m1348).}\n",
      "Match {horror(m1348).}\n",
      "Clause horror(m1348).\n",
      "Substitution {A: u777, B: m1348, Movie: m1348}\n",
      "Atoms []\n",
      "Recommandations pour u777:\n",
      "         0      1      2      3\n",
      "Movie  m47  m2987  m1259  m1348\n"
     ]
    }
   ],
   "source": [
    "from andante.program import AndanteProgram\n",
    "\n",
    "# Chemin vers le fichier Prolog\n",
    "file_path = 'prolog_partitions_six/prolog_program_partition_5.pl'\n",
    "\n",
    "# Ajouter un nouvel utilisateur au programme\n",
    "new_user_id = \"u777\"\n",
    "new_user_age = \"b25to34\"  # Groupe d'âge: 25-34\n",
    "new_user_gender = \"m\"  # Sexe: Masculin\n",
    "new_movie_id = \"m777\"\n",
    "user_movie_genre = \"action\"\n",
    "rating_movie = 4\n",
    "\n",
    "add_new_user_to_existing_program(file_path, new_user_id, new_user_age, new_user_gender, new_movie_id, user_movie_genre, rating_movie)\n",
    "\n",
    "# Charger le programme Prolog avec les nouvelles données\n",
    "ap = AndanteProgram.build_from(file_path)\n",
    "\n",
    "# Définir les paramètres pour l'inférence\n",
    "ap.set('verbose', 1)\n",
    "ap.set('h', 100)\n",
    "\n",
    "# Générer les règles si elles ne sont pas déjà générées\n",
    "induced_rules = ap.induce(update_knowledge=True, logging=True, verbose=0)\n",
    "\n",
    "# Recommander un film pour le nouvel utilisateur\n",
    "result, df = ap.query(f\"recommend({new_user_id}, Movie).\")\n",
    "\n",
    "# Afficher les recommandations\n",
    "if result:\n",
    "    print(f\"Recommandations pour {new_user_id}:\")\n",
    "    print(df)\n",
    "else:\n",
    "    print(f\"Aucune recommandation trouvée pour {new_user_id}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine rules from different partitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing prolog_partitions_six/prolog_program_partition_1.pl...\n",
      "Processing prolog_partitions_six/prolog_program_partition_2.pl...\n",
      "Processing prolog_partitions_six/prolog_program_partition_3.pl...\n",
      "Processing prolog_partitions_six/prolog_program_partition_4.pl...\n",
      "Processing prolog_partitions_six/prolog_program_partition_5.pl...\n",
      "Processing prolog_partitions_six/prolog_program_partition_6.pl...\n",
      "recommend(A, B) :- b25to34(A), comedy(B).\n",
      "recommend(A, B) :- crime(B).\n",
      "recommend(A, B) :- f(A).\n",
      "recommend(A, B) :- b25to34(A), action(B).\n",
      "recommend(A, B) :- b45to49(A).\n",
      "recommend(A, B) :- b18to24(A), drama(B).\n",
      "recommend(A, B) :- horror(B).\n",
      "recommend(A, B) :- b25to34(A), f(A).\n",
      "recommend(A, B) :- adventure(B).\n",
      "recommend(A, B) :- m(A), drama(B).\n",
      "Combined rules saved to combined_rules.txt\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from andante.program import AndanteProgram\n",
    "from andante.collections import OrderedSet\n",
    "from andante.logic_concepts import Clause\n",
    "\n",
    "from andante.knowledge import TreeShapedKnowledge\n",
    "# Define the directory containing the Prolog partition files\n",
    "prolog_directory = \"prolog_partitions_six\"\n",
    "\n",
    "# List of partition file names\n",
    "partition_files = [\n",
    "    f\"{prolog_directory}/prolog_program_partition_{i+1}.pl\"\n",
    "    for i in range(6)  # Assuming 6 partitions, adjust as needed\n",
    "]\n",
    "\n",
    "# Initialize an OrderedSet to hold all unique rules\n",
    "all_rules = OrderedSet()\n",
    "\n",
    "# Iterate over each partition file and induce rules\n",
    "for partition_file in partition_files:\n",
    "    print(f\"Processing {partition_file}...\")\n",
    "    # Build the AndanteProgram from the current partition file\n",
    "    ap = AndanteProgram.build_from(partition_file)\n",
    "    \n",
    "    # Induce rules and update knowledge\n",
    "    induced_knowledge = ap.induce(update_knowledge=True, logging=True, verbose=0)\n",
    "    \n",
    "    # If induced_knowledge is a TreeShapedKnowledge, extract its clauses\n",
    "    if isinstance(induced_knowledge, TreeShapedKnowledge):\n",
    "        for clause in induced_knowledge.clauses:\n",
    "            if isinstance(clause, Clause):\n",
    "                all_rules.add(clause)\n",
    "    else:\n",
    "        print(f\"Unexpected type for induced_rules: {type(induced_knowledge)}\")\n",
    "\n",
    "# Output the combined rules\n",
    "for rule in all_rules:\n",
    "    print(rule)\n",
    "\n",
    "# Optionally, save the combined rules to a file\n",
    "with open(\"combined_rules.txt\", \"w\") as f:\n",
    "    for rule in all_rules:\n",
    "        f.write(str(rule) + \"\\n\")\n",
    "\n",
    "print(\"Combined rules saved to combined_rules.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Union with normalization and unification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing prolog_partitions_six/prolog_program_partition_1.pl...\n",
      "Processing prolog_partitions_six/prolog_program_partition_2.pl...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Predicate' object has no attribute 'predicate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[136], line 66\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m clause \u001b[38;5;129;01min\u001b[39;00m induced_knowledge\u001b[38;5;241m.\u001b[39mclauses:\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(clause, Clause):\n\u001b[1;32m---> 66\u001b[0m             normalized_clause \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize_clause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclause\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m             all_rules\u001b[38;5;241m.\u001b[39madd(normalized_clause)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[136], line 38\u001b[0m, in \u001b[0;36mnormalize_clause\u001b[1;34m(clause)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m             new_terms\u001b[38;5;241m.\u001b[39mappend(term)\n\u001b[1;32m---> 38\u001b[0m     new_body\u001b[38;5;241m.\u001b[39mappend(Atom(\u001b[43matom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredicate\u001b[49m, new_terms))\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Apply the same mapping to the head of the clause\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clause\u001b[38;5;241m.\u001b[39mhead:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Predicate' object has no attribute 'predicate'"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from andante.program import AndanteProgram\n",
    "from andante.collections import OrderedSet\n",
    "from andante.logic_concepts import Clause, Atom, Variable, Predicate\n",
    "from andante.knowledge import TreeShapedKnowledge\n",
    "\n",
    "# Define the directory containing the Prolog partition files\n",
    "prolog_directory = \"prolog_partitions_six\"\n",
    "\n",
    "# List of partition file names\n",
    "partition_files = [\n",
    "    f\"{prolog_directory}/prolog_program_partition_{i+1}.pl\"\n",
    "    for i in range(6)  # Assuming 6 partitions, adjust as needed\n",
    "]\n",
    "\n",
    "# Initialize an OrderedSet to hold all unique rules\n",
    "all_rules = OrderedSet()\n",
    "\n",
    "# Function to normalize and unify clauses\n",
    "def normalize_clause(clause):\n",
    "    # Sort the literals in the body of the clause for consistent ordering\n",
    "    sorted_body = sorted(clause.body, key=lambda atom: str(atom))\n",
    "\n",
    "    # Standardize variable names: use a consistent naming scheme, e.g., A, B, C...\n",
    "    var_mapping = {}\n",
    "    new_body = []\n",
    "    new_head = clause.head\n",
    "\n",
    "    for atom in sorted_body:\n",
    "        new_terms = []\n",
    "        for term in atom:\n",
    "            if isinstance(term, Variable):\n",
    "                if term not in var_mapping:\n",
    "                    var_mapping[term] = Variable(chr(ord('A') + len(var_mapping)))\n",
    "                new_terms.append(var_mapping[term])\n",
    "            else:\n",
    "                new_terms.append(term)\n",
    "        new_body.append(Atom(atom.predicate, new_terms))\n",
    "\n",
    "    # Apply the same mapping to the head of the clause\n",
    "    if clause.head:\n",
    "        new_head_terms = []\n",
    "        for term in clause.head.terms:\n",
    "            if isinstance(term, Variable):\n",
    "                new_head_terms.append(var_mapping.get(term, term))\n",
    "            else:\n",
    "                new_head_terms.append(term)\n",
    "        new_head = Atom(clause.head.predicate, new_head_terms)\n",
    "\n",
    "    # Return the normalized clause\n",
    "    return Clause(new_head, new_body)\n",
    "\n",
    "# Iterate over each partition file and induce rules\n",
    "for partition_file in partition_files:\n",
    "    print(f\"Processing {partition_file}...\")\n",
    "    # Build the AndanteProgram from the current partition file\n",
    "    ap = AndanteProgram.build_from(partition_file)\n",
    "    \n",
    "    # Induce rules and update knowledge\n",
    "    induced_knowledge = ap.induce(update_knowledge=True, logging=True, verbose=0)\n",
    "    \n",
    "    # If induced_knowledge is a TreeShapedKnowledge, extract its clauses\n",
    "    if isinstance(induced_knowledge, TreeShapedKnowledge):\n",
    "        for clause in induced_knowledge.clauses:\n",
    "            if isinstance(clause, Clause):\n",
    "                normalized_clause = normalize_clause(clause)\n",
    "                all_rules.add(normalized_clause)\n",
    "    else:\n",
    "        print(f\"Unexpected type for induced_rules: {type(induced_knowledge)}\")\n",
    "\n",
    "# Function to check for redundancy and remove duplicates\n",
    "def remove_redundancy(rules):\n",
    "    unique_rules = OrderedSet()\n",
    "    for rule in rules:\n",
    "        if rule not in unique_rules:\n",
    "            unique_rules.add(rule)\n",
    "    return unique_rules\n",
    "\n",
    "# Remove redundancy from all_rules\n",
    "all_rules = remove_redundancy(all_rules)\n",
    "\n",
    "# Output the combined, normalized, and unique rules\n",
    "for rule in all_rules:\n",
    "    print(rule)\n",
    "\n",
    "# Optionally, save the combined rules to a file\n",
    "with open(\"combined_rules.txt\", \"w\") as f:\n",
    "    for rule in all_rules:\n",
    "        f.write(str(rule) + \"\\n\")\n",
    "\n",
    "print(\"Combined, normalized, and unique rules saved to combined_rules_normalized.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
