{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.csv_loader import CSVLoader\n",
    "from models.products.product_registry import ProductRegistry\n",
    "from models.products.product_mapping_row import ProductMappingRow\n",
    "from models.products.product_row import ProductRow\n",
    "\n",
    "product_registry = ProductRegistry(CSVLoader(ProductRow).read(), CSVLoader(ProductMappingRow).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.users.user_registry import UserRegistry\n",
    "from models.users.user_mapping_row import UserMappingRow\n",
    "from models.users.user_row import UserRow\n",
    "\n",
    "user_registry = UserRegistry(CSVLoader(UserRow).read(), CSVLoader(UserMappingRow).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ratings.rating_registry import RatingRegistry\n",
    "from models.ratings.rating_row import RatingRow\n",
    "\n",
    "rating_registry = RatingRegistry(CSVLoader(RatingRow).read(), user_registry, product_registry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rec method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.reco.reco_factory import RecoFactory\n",
    "import os \n",
    "from paths import PATHS\n",
    "\n",
    "    \n",
    "user_recos = dict()\n",
    "for json_file_name in os.listdir(PATHS[\"recommendations\"]):\n",
    "    user_id = int(json_file_name.split(\"_\")[-1].split(\".\")[0])\n",
    "    user_reco_path = os.path.join(PATHS[\"recommendations\"], json_file_name)\n",
    "    user_recos[user_id] = RecoFactory.from_file(user_reco_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecoPath(nodes=[RecoNode(type='user', entity_id=33), RecoNode(type='product', entity_id=2346), RecoNode(type='user', entity_id=2678), RecoNode(type='product', entity_id=1762)], rels=[RecoRel(in_node=RecoNode(type='user', entity_id=33), relation='watched', out_node=RecoNode(type='product', entity_id=2346)), RecoRel(in_node=RecoNode(type='user', entity_id=2678), relation='watched', out_node=RecoNode(type='product', entity_id=2346)), RecoRel(in_node=RecoNode(type='user', entity_id=2678), relation='watched', out_node=RecoNode(type='product', entity_id=1762))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_recos[33][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import List\n",
    "\n",
    "# from models.reco.reco_path import RecoPath\n",
    "\n",
    "\n",
    "# def generate_facts(path: RecoPath):\n",
    "#     facts_txt = \"% Path: \\n\"\n",
    "#     for rel in path.rels:\n",
    "#         facts_txt += rel.to_facts() + \"\\n\"\n",
    "#         user = user_registry.find_by_eid(rel.in_node.entity_id)\n",
    "#         product = product_registry.find_by_eid(rel.out_node.entity_id)\n",
    "#         facts_txt += rating_registry.find_user_product_rating(user.uid, product.pid).to_facts() + \"\\n\"\n",
    "#     facts_txt += \"% Background Knowledge: \\n\"\n",
    "#     for node in path.nodes:\n",
    "#         if node.type == \"user\":\n",
    "#             user = user_registry.find_by_eid(node.entity_id)\n",
    "#             facts_txt += user.to_facts() + \"\\n\"\n",
    "#         elif node.type == \"product\":\n",
    "#             product = product_registry.find_by_eid(node.entity_id)\n",
    "#             facts_txt += product.to_facts() + \"\\n\"\n",
    "#     return facts_txt\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(generate_facts(user_recos[33][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "HUGGINGFACEHUB_API_TOKEN = os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/balfroim/.cache/pypoetry/virtualenvs/trail24-UZVMavSK-py3.10/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceEndpoint` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the from langchain-huggingface package and should be used instead. To use it run `pip install -U from langchain-huggingface` and import as `from from langchain_huggingface import llms import HuggingFaceEndpoint`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/balfroim/.cache/huggingface/token\n",
      "Login successful\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/balfroim/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "reasoning_llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    # repo_id=\"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    **{\n",
    "        \"max_new_tokens\": 2048,\n",
    "        \"temperature\": 0.1,\n",
    "        \"top_k\": 50,\n",
    "        # \"top_p\": 0.9,\n",
    "        # \"repetition_penalty\": 1.1\n",
    "    },\n",
    ")\n",
    "\n",
    "answering_llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    # repo_id=\"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    **{\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"temperature\": 0.4,\n",
    "        \"top_k\": 30,\n",
    "        # \"top_p\": 0.8,\n",
    "        # \"repetition_penalty\": 1.05\n",
    "    },\n",
    ")\n",
    "\n",
    "reasoning_template = \"\"\"You are an expert in graph-based recommender systems.\n",
    "You try to follow the following explanation goal:\n",
    "1. **Transparency:** Clearly explain how the recommendation algorithm made the decision.\n",
    "2. **Scrutability:** Allow the user to provide feedback if the recommendation seems incorrect.\n",
    "3. **Trust:** Build user’s confidence in the recommender system.\n",
    "4. **Effectiveness:** Help user make informed decisions about the recommendation.\n",
    "5. **Efficiency:** Provide a quick explanation to facilitate faster decision-making.\n",
    "6. **Persuasiveness:** Convince user of the relevance of the recommendation.\n",
    "7. **Satisfaction:** Enhance the ease of use and overall experience of the system for the user.\n",
    "Given the background knowledge: \n",
    "{context}\n",
    "Explain, step by step, why the movie {product} was recommended to the user {user}.\n",
    "\"\"\"\n",
    "\n",
    "reasoning_prompt = PromptTemplate.from_template(reasoning_template)\n",
    "\n",
    "answer_template = \"\"\"Based on the reasoning provided: {reasoning}.\n",
    "You are a friendly and helpful recommender system.\n",
    "Give a clear and concise explanation of why the movie {product} was recommended to the user {user}:\n",
    "\"\"\"\n",
    "answer_prompt = PromptTemplate.from_template(answer_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_chain = reasoning_prompt | reasoning_llm\n",
    "answering_chain = answer_prompt | answering_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommendation.registry_handler import RegistryHandler\n",
    "from recommendation.explainers.cot_explainer import COTExplainer\n",
    "\n",
    "\n",
    "registry_handler = RegistryHandler(product_registry, user_registry, rating_registry)\n",
    "cot_explainer = COTExplainer(registry_handler, reasoning_chain, answering_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = user_recos[33][1]\n",
    "# cot_explainer._prepare_input(path, [\"name\"])\n",
    "continuation, trace = cot_explainer.explain(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reasoning prompt:\n",
      "You are an expert in graph-based recommender systems.\n",
      "You try to follow the following explanation goal:\n",
      "1. **Transparency:** Clearly explain how the recommendation algorithm made the decision.\n",
      "2. **Scrutability:** Allow the user to provide feedback if the recommendation seems incorrect.\n",
      "3. **Trust:** Build user’s confidence in the recommender system.\n",
      "4. **Effectiveness:** Help user make informed decisions about the recommendation.\n",
      "5. **Efficiency:** Provide a quick explanation to facilitate faster decision-making.\n",
      "6. **Persuasiveness:** Convince user of the relevance of the recommendation.\n",
      "7. **Satisfaction:** Enhance the ease of use and overall experience of the system for the user.\n",
      "Given the background knowledge: \n",
      "watched(User33, Product2254)\n",
      "rated(User33, Product2254, 2)\n",
      "watched(User1100, Product2254)\n",
      "rated(User1100, Product2254, 4)\n",
      "watched(User1100, Product1359)\n",
      "rated(User1100, Product1359, 5)\n",
      "gender(User33, F)\n",
      "age(User33, 18-24)\n",
      "name(Product2254, \"Omen, The (1976)\")\n",
      "genre(Product2254, Horror)\n",
      "gender(User1100, M)\n",
      "age(User1100, 35-44)\n",
      "name(Product1359, \"Star Wars: Episode IV - A New Hope (1977)\")\n",
      "genre(Product1359, Action)\n",
      "Explain, step by step, why the movie Product1359 was recommended to the user User33.\n",
      "\n",
      "reasoning completion:\n",
      "\n",
      "answer prompt:\n",
      "Based on the reasoning provided: .\n",
      "You are a friendly and helpful recommender system.\n",
      "Give a clear and concise explanation of why the movie Product1359 was recommended to the user User33:\n",
      "\n",
      "answer completion:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"reasoning prompt:\")\n",
    "print(trace.reasoning_trace.prompt)\n",
    "print(\"reasoning completion:\")\n",
    "print(trace.reasoning_trace.completion)\n",
    "print(\"answer prompt:\")\n",
    "print(trace.answering_trace.prompt)\n",
    "print(\"answer completion:\")\n",
    "print(trace.answering_trace.completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User33 was recommended the movie Product1762 because they previously enjoyed movies in the same genre, such as Product123 and Product456. Additionally, User33 has a history of rating movies with similar themes highly, such as Product789 and Product101. Product1762 falls into both of these categories, making it a strong recommendation for User33.\n",
      "----------------\n",
      "\n",
      "User33 was recommended the movie Product1762 because they previously enjoyed movies in the same genre, such as Product123 and Product456. Additionally, User33 has a history of rating movies with similar themes highly, such as Product789 and Product101. Product1762 falls into both of these categories, making it a strong recommendation for User33.\n"
     ]
    }
   ],
   "source": [
    "path = user_recos[33][0]\n",
    "continuation2, _ = cot_explainer.explain(path)\n",
    "continuation3, _ = cot_explainer.explain(path, [\"name\"])\n",
    "\n",
    "print(continuation2)\n",
    "print('----------------')\n",
    "print(continuation3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
